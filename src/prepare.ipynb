{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing common packages\n",
    "\n",
    "import os, sys, random\n",
    "import re, string, contractions\n",
    "import nltk, sklearn\n",
    "import csv\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from the file to a single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(\"../data/SMSSpamCollection\")\n",
    "sms_data_list = data_file.readlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the list into a list of [label, data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham', 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...']\n"
     ]
    }
   ],
   "source": [
    "sms_labelled_data = [[i.split(\"\\t\")[0], i.split(\"\\t\")[1].split(\"\\n\")[0]] for i in sms_data_list]\n",
    "print(sms_labelled_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to get words from the sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(sent):\n",
    "    sent = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', sent, flags=re.MULTILINE) # Remove urls starting with http\n",
    "    sent = re.sub(r'^http?:\\/\\/.*[\\r\\n]*', '', sent, flags=re.MULTILINE) # Remove urls starting with https\n",
    "    sent = contractions.fix(sent, slang=True) # Replace contractions with words\n",
    "    sent = ''.join([i for i in sent if not i.isdigit()]) # Remove numbers\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokenized_words = tokenizer.tokenize(sent) # Remove all punctuation marks (don't have to worry about contractions)\n",
    "    return tokenized_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to return a vocabulary (with number of occurences) upon given an sms as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_sms(sms):\n",
    "    words_list = get_words(sms)\n",
    "    \n",
    "    stopwords = list(nltk.corpus.stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    temp_list = []\n",
    "\n",
    "    for word in words_list:\n",
    "        if len(word) > 1 and word.lower() not in stopwords:\n",
    "            word = lemmatizer.lemmatize(word.lower())\n",
    "            temp_list.append(word.lower())\n",
    "\n",
    "    return temp_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the defined functions to convert the labelled list of sms into a labelled list of vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ham',\n",
       " ['go',\n",
       "  'jurong',\n",
       "  'point',\n",
       "  'crazy',\n",
       "  'available',\n",
       "  'bugis',\n",
       "  'great',\n",
       "  'world',\n",
       "  'la',\n",
       "  'buffet',\n",
       "  'cine',\n",
       "  'got',\n",
       "  'amore',\n",
       "  'wat'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_labels = []\n",
    "sms_words = []\n",
    "\n",
    "for item in sms_labelled_data:\n",
    "    word_list = get_tokenized_sms(item[1])\n",
    "\n",
    "    sms_labels.append(item[0])\n",
    "    sms_words.append(word_list)\n",
    "\n",
    "sms_labels[0], sms_words[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to save the labels and words as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(filename, x_data, y_data):\n",
    "    combined_data = []\n",
    "    \n",
    "    for i in range(len(y_data)):\n",
    "        temp = []\n",
    "        temp.append(y_data[i])\n",
    "        temp = temp + x_data[i]\n",
    "        combined_data.append(temp)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        write = csv.writer(f)\n",
    "        write.writerows(combined_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining all the above preprocessing steps into one function to save a raw_data.csv file from the given text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_from_txt(file_path):\n",
    "    data_file = open(file_path)\n",
    "    sms_data_list = data_file.readlines()\n",
    "    sms_labelled_data = [[i.split(\"\\t\")[0], i.split(\"\\t\")[1].split(\"\\n\")[0]] for i in sms_data_list]\n",
    "\n",
    "    sms_labels = []\n",
    "    sms_words = []\n",
    "\n",
    "    for item in sms_labelled_data:\n",
    "        word_list = get_tokenized_sms(item[1])\n",
    "\n",
    "        sms_labels.append(item[0])\n",
    "        sms_words.append(word_list)\n",
    "\n",
    "    save_csv(\"../data/raw_data.csv\", sms_words, sms_labels)\n",
    "\n",
    "    return sms_labels, sms_words\n",
    "\n",
    "sms_labels, sms_words = get_csv_from_txt(\"../data/SMSSpamCollection\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the raw_data into lists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to load data from csv to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_from_csv(file_path):\n",
    "    with open(file_path, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        sms_words = list(reader)\n",
    "\n",
    "    sms_labels = [x[0] for x in sms_words]\n",
    "\n",
    "    for x in sms_words:\n",
    "        del x[0]\n",
    "\n",
    "    return sms_labels, sms_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into train/validation/test datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to split data into train/val/test sets and saving as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(data_x, data_y, val_per, test_per, tr_path, val_path, te_path, random_seed):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=test_per, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=val_per/(1-test_per), shuffle=True, random_state=random_seed)\n",
    "\n",
    "    save_csv(tr_path, x_train, y_train)\n",
    "    save_csv(val_path, x_val, y_val)\n",
    "    save_csv(te_path, x_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining file paths for train/val/test csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/train_data.csv\"\n",
    "val_path = \"../data/val_data.csv\"\n",
    "test_path = \"../data/test_data.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data using random seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_split(sms_words, sms_labels, 0.15, 0.15, train_path, val_path, test_path, 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the split csv using dvc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m             <\u001b[36mhttps://dvc.org/doc/user-guide/analytics\u001b[39m>              \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: <\u001b[36mhttps://dvc.org/doc\u001b[39m>\n",
      "- Get help and share ideas: <\u001b[36mhttps://dvc.org/chat\u001b[39m>\n",
      "- Star us on GitHub: <\u001b[36mhttps://github.com/iterative/dvc\u001b[39m>\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd .. && dvc init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add all three csv files to dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l                                                                          \u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "  0% Checking cache in '/mnt/vol_d/VSCode_Workspace/cmi_applied_ml/.dvc/cache'| \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Transferring                          0/? [00:00<?,     ?file/s]\u001b[A\n",
      "  0%|          |Transferring                          0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00,  7.90file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add ../data/train_data.csv.dvc ../data/.gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Checking graph                                                   \u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "  0% Checking cache in '/mnt/vol_d/VSCode_Workspace/cmi_applied_ml/.dvc/cache'| \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Transferring                          0/? [00:00<?,     ?file/s]\u001b[A\n",
      "  0%|          |Transferring                          0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 23.06file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add ../data/val_data.csv.dvc ../data/.gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Checking graph                                                   \u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "  0% Checking cache in '/mnt/vol_d/VSCode_Workspace/cmi_applied_ml/.dvc/cache'| \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Transferring                          0/? [00:00<?,     ?file/s]\u001b[A\n",
      "  0%|          |Transferring                          0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 23.75file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add ../data/.gitignore ../data/test_data.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add ../data/train_data.csv\n",
    "!dvc add ../data/val_data.csv\n",
    "!dvc add ../data/test_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc config core.autostage true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding google drive folder as a remote data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 'myremote' as a default remote.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd .. && dvc remote add --default myremote gdrive://1MypipdcBtjmYnO3OQQmLxKM3SWfwmE2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc remote modify myremote gdrive_acknowledge_abuse true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pushing dvc tracked files to remote storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0% Transferring|                                   |0/3 [00:00<?,     ?file/s]\n",
      "!\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_app0.00/? [00:00<?,        ?B/s]\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_0.00/205k [00:00<?,        ?B/s]\u001b[A\n",
      " 33% Transferring|██████████▎                    |1/3 [00:04<00:08,  4.05s/file]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_app0.00/? [00:00<?,        ?B/s]\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi0.00/44.6k [00:00<?,        ?B/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_app0.00/? [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi0.00/45.8k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      " 18%|█▊        |/mnt/vol_d/VSCode_Workspac8.00k/44.6k [00:02<00:10,    3.68kB/s]\u001b[A\n",
      "\n",
      " 67% Transferring|████████████████████▋          |2/3 [00:07<00:03,  3.85s/file]\u001b[A\u001b[A\n",
      "100% Transferring|███████████████████████████████|3/3 [00:09<00:00,  2.70s/file]\u001b[A\n",
      "\n",
      "3 files pushed                                                                  \u001b[A\u001b[A\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc push"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting again using a different random seed (37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_split(sms_words, sms_labels, 0.15, 0.15, train_path, val_path, test_path, 37)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking changes and commiting changes in dvc (commiting was done in terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/test_data.csv.dvc:                                            core\u001b[39m>\n",
      "\tchanged outs:\n",
      "\t\tmodified:           ../data/test_data.csv\n",
      "../data/train_data.csv.dvc:\n",
      "\tchanged outs:\n",
      "\t\tmodified:           ../data/train_data.csv\n",
      "../data/val_data.csv.dvc:\n",
      "\tchanged outs:\n",
      "\t\tmodified:           ../data/val_data.csv\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc status"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkout different Versions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting git log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcommit 3b04052025e336e41dba9b34c19979ddde504f5c\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mmain\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/main\u001b[m\u001b[33m)\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 18:10:18 2023 +0530\n",
      "\n",
      "    Second Split 37\n",
      "\n",
      "\u001b[33mcommit 7eda936db5773bfd8f14a81c222eba24b13ed5e5\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 18:09:55 2023 +0530\n",
      "\n",
      "    seond split\n",
      "\n",
      "\u001b[33mcommit ebb8d9e034a82321295bc3ba7b8044ffe3c8cfb4\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: v1.0\u001b[m\u001b[33m)\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 17:53:30 2023 +0530\n",
      "\n",
      "    First Split 42\n",
      "\n",
      "\u001b[33mcommit d1ab32da26043d4a4ee492035b17ab39ba746064\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 17:52:31 2023 +0530\n",
      "\n",
      "    till first split\n",
      "\n",
      "\u001b[33mcommit 22b95fa3548542decf4a9c302cbbfc08dc0970dc\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 17:52:01 2023 +0530\n",
      "\n",
      "    data dvc init\n",
      "\n",
      "\u001b[33mcommit d7f0ba22fcb7c6a8868c4760762a0fdeca888f43\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 17:51:48 2023 +0530\n",
      "\n",
      "    dvc init\n",
      "\n",
      "\u001b[33mcommit 3394d180512f8f0126d18fcef828271e5de7fd06\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 17:49:59 2023 +0530\n",
      "\n",
      "    fresh_start\n",
      "\n",
      "\u001b[33mcommit 71a6ce6b717b3eb26eed85c6eff7947d1bde1f75\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 17:42:54 2023 +0530\n",
      "\n",
      "    first_split\n",
      "\n",
      "\u001b[33mcommit adf6873f0df97342132ecf07a352e3680a2610e8\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 17:38:58 2023 +0530\n",
      "\n",
      "    fresh start\n",
      "\n",
      "\u001b[33mcommit 3e81394cf7f4c565d57dc74a6ba742410f141acb\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 17:35:09 2023 +0530\n",
      "\n",
      "    split files\n",
      "\n",
      "\u001b[33mcommit 3c2a93e6dc371b61a8af3dafd3e5cd8f40fb18b6\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 17:34:43 2023 +0530\n",
      "\n",
      "    dvc files\n",
      "\n",
      "\u001b[33mcommit f17b3cc2d62843e7d96222bd0ef88815c3aa84ce\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Sun Feb 26 17:24:20 2023 +0530\n",
      "\n",
      "    fresh_start\n",
      "\n",
      "\u001b[33mcommit bb9ae72470425870e1bb4f27cd3cc8afe7c8e14a\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Wed Feb 1 00:17:52 2023 +0530\n",
      "\n",
      "    v1.1\n",
      "\n",
      "\u001b[33mcommit 2e526b523efb291ceedd94d1435489ab1fdf73e1\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Tue Jan 31 23:58:51 2023 +0530\n",
      "\n",
      "    v1.0\n",
      "\n",
      "\u001b[33mcommit 60c70cdbbd5ef6de7989a9aaa36024ce1724b3e9\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Tue Jan 31 23:28:54 2023 +0530\n",
      "\n",
      "    v1.0\n",
      "\n",
      "\u001b[33mcommit 68f2e5bd38199d937f1c12e4d43156d82d9e0609\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Tue Jan 31 22:24:30 2023 +0530\n",
      "\n",
      "    v1.0\n",
      "\n",
      "\u001b[33mcommit 627d821f1335e52efaab04a42c1000a51c3dde31\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Tue Jan 31 22:24:15 2023 +0530\n",
      "\n",
      "    v1.0\n",
      "\n",
      "\u001b[33mcommit 37ef5e3d24f4bd6f9d297b0c151e136bcfac43ef\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Tue Jan 31 22:21:35 2023 +0530\n",
      "\n",
      "    processed data list of words\n",
      "\n",
      "\u001b[33mcommit efa0fa3f20b5a48f88dac07e21376814192f7735\u001b[m\n",
      "Author: Rohan Dharmadhikari <drohan.1994@gmail.com>\n",
      "Date:   Tue Jan 31 22:21:19 2023 +0530\n",
      "\n",
      "    raw_data\n"
     ]
    }
   ],
   "source": [
    "!git log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out version - \"First Split 42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was 3b04052 Second Split 37\n",
      "HEAD is now at ebb8d9e First Split 42\n"
     ]
    }
   ],
   "source": [
    "!git checkout ebb8d9e034a82321295bc3ba7b8044ffe3c8cfb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0% Checkout|                                       |0/1 [00:00<?,     ?file/s]\n",
      "!\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_app0.00/? [00:00<?,        ?B/s]\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_0.00/205k [00:00<?,        ?B/s]\u001b[A\n",
      "100% Checkout|███████████████████████████████████|1/1 [00:00<00:00, 15.01file/s]\u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_app0.00/? [00:00<?,        ?B/s]\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi0.00/45.8k [00:00<?,        ?B/s]\u001b[A\n",
      "  0% Checkout|                                   |2/? [00:00<00:00, 24.22file/s]\u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_app0.00/? [00:00<?,        ?B/s]\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi0.00/44.6k [00:00<?,        ?B/s]\u001b[A\n",
      "\u001b[33mM\u001b[0m       ..\u001b[35m/data/\u001b[0m\u001b[95mtrain_data.csv\u001b[0m                       \u001b[A\n",
      "\u001b[33mM\u001b[0m       ..\u001b[35m/data/\u001b[0m\u001b[95mtest_data.csv\u001b[0m\n",
      "\u001b[33mM\u001b[0m       ..\u001b[35m/data/\u001b[0m\u001b[95mval_data.csv\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc checkout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting distribution of sms_labels in split files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_dist(file_path):\n",
    "    file_labels, file_words = get_list_from_csv(file_path)\n",
    "\n",
    "    ham_count = file_labels.count(\"ham\")\n",
    "    spam_count = file_labels.count(\"spam\")\n",
    "\n",
    "    print(\"Ham: {}, Spam: {}\".format(ham_count, spam_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Split (42)\n",
      "Training dataset:\n",
      "Ham: 3403, Spam: 498\n",
      "Validation dataset:\n",
      "Ham: 712, Spam: 124\n",
      "Testing dataset:\n",
      "Ham: 712, Spam: 125\n"
     ]
    }
   ],
   "source": [
    "print(\"First Split (42)\")\n",
    "print(\"Training dataset:\")\n",
    "get_label_dist(train_path)\n",
    "print(\"Validation dataset:\")\n",
    "get_label_dist(val_path)\n",
    "print(\"Testing dataset:\")\n",
    "get_label_dist(test_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out version - \"Second Split 37\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was ebb8d9e First Split 42\n",
      "HEAD is now at 3b04052 Second Split 37\n"
     ]
    }
   ],
   "source": [
    "!git checkout 3b04052025e336e41dba9b34c19979ddde504f5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0% Checkout|                                       |0/1 [00:00<?,     ?file/s]\n",
      "!\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_app0.00/? [00:00<?,        ?B/s]\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi0.00/44.0k [00:00<?,        ?B/s]\u001b[A\n",
      "100% Checkout|███████████████████████████████████|1/1 [00:00<00:00, 12.54file/s]\u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_app0.00/? [00:00<?,        ?B/s]\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_0.00/207k [00:00<?,        ?B/s]\u001b[A\n",
      "  0% Checkout|                                   |2/? [00:00<00:00, 20.54file/s]\u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi_app0.00/? [00:00<?,        ?B/s]\u001b[A\n",
      "  0%|          |/mnt/vol_d/VSCode_Workspace/cmi0.00/43.6k [00:00<?,        ?B/s]\u001b[A\n",
      "\u001b[33mM\u001b[0m       ..\u001b[35m/data/\u001b[0m\u001b[95mtest_data.csv\u001b[0m                        \u001b[A\n",
      "\u001b[33mM\u001b[0m       ..\u001b[35m/data/\u001b[0m\u001b[95mtrain_data.csv\u001b[0m\n",
      "\u001b[33mM\u001b[0m       ..\u001b[35m/data/\u001b[0m\u001b[95mval_data.csv\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Split (37)\n",
      "Training dataset:\n",
      "Ham: 3394, Spam: 507\n",
      "Validation dataset:\n",
      "Ham: 719, Spam: 117\n",
      "Testing dataset:\n",
      "Ham: 714, Spam: 123\n"
     ]
    }
   ],
   "source": [
    "print(\"Second Split (37)\")\n",
    "print(\"Training dataset:\")\n",
    "get_label_dist(train_path)\n",
    "print(\"Validation dataset:\")\n",
    "get_label_dist(val_path)\n",
    "print(\"Testing dataset:\")\n",
    "get_label_dist(test_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_cmi_all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb51b6b13e8232a64b369b5696b9d41218df7738edf9356f9fbcee5c06010241"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
